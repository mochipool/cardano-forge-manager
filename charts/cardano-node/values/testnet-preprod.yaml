# Testnet (Preprod) Block Producer
# This configuration is optimized for testing and development on the preprod testnet
# Lower resource requirements and faster sync with Mithril

# ===========================================
# REPLICA CONFIGURATION
# ===========================================
# Fewer replicas for testnet
replicaCount: 2

# ===========================================
# CARDANO NODE CONFIGURATION
# ===========================================
cardanoNode:
  network: "preprod"
  magic: "1"
  
  # Block producer mode
  blockProducer: true
  startAsNonProducing: true
  
  # Enable Mithril for fast initial sync
  mithril:
    enabled: true
    restoreSnapshot: true
    clientVersion: "0.8.11"
    aggregatorEndpoint: "https://aggregator.release-preprod.api.mithril.network/aggregator"

# ===========================================
# FORGE MANAGER V2.0
# ===========================================
forgeManager:
  enabled: true
  
  # Basic settings
  metricsPort: 8000
  socketWaitTimeout: 120
  sleepInterval: 10
  logLevel: "DEBUG"  # More verbose for testing
  
  # Single-tenant testnet deployment
  multiTenant:
    enabled: true
    
    pool:
      id: "pool1testpreproddevelopment11111111111111111111111"  # Replace with your preprod pool ID
      idHex: ""
      name: "Test Pool Preprod"
      ticker: "TSTPP"
    
    application:
      type: "block-producer"
      environment: "development"
  
  # No cluster management for simple testnet
  clusterManagement:
    enabled: false
  
  # Legacy CRD for local leader election
  legacy:
    crd:
      cardanoLeader:
        enabled: true

# ===========================================
# STORAGE CONFIGURATION
# ===========================================
persistence:
  enabled: true
  size: 150Gi  # Preprod is smaller than mainnet
  # storageClass: "standard"

# ===========================================
# RESOURCE CONFIGURATION (Reduced)
# ===========================================
resources:
  cardanoNode:
    limits:
      cpu: 2000m
      memory: 8Gi
    requests:
      cpu: 1000m
      memory: 6Gi
  
  forgeManager:
    limits:
      cpu: 200m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 256Mi

# ===========================================
# SERVICE CONFIGURATION
# ===========================================
service:
  p2p:
    type: ClusterIP  # No external load balancer for testnet
    annotations: {}

# ===========================================
# MONITORING
# ===========================================
monitoring:
  enabled: true
  serviceMonitor:
    enabled: false  # Disable ServiceMonitor for testnet

# ===========================================
# POD LABELS
# ===========================================
podLabels:
  network: "preprod"
  pool-id: "pool1test"
  environment: "development"

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "12798"

# ===========================================
# POD ANTI-AFFINITY (Optional for testnet)
# ===========================================
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 50
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - cardano-node
              - key: network
                operator: In
                values:
                  - preprod
          topologyKey: kubernetes.io/hostname

# ===========================================
# DEPLOYMENT INSTRUCTIONS
# ===========================================
# This example demonstrates a preprod testnet block producer with:
# - Reduced resource requirements (2 CPU, 8GB RAM)
# - Mithril snapshot restore for fast sync
# - 2 replicas for basic HA
# - Debug logging enabled
# - No cluster management (single cluster)
#
# 1. Install CRDs (once):
#    helm install cardano-forge-crds charts/cardano-forge-crds \
#      --namespace cardano-system --create-namespace
#
# 2. Create namespace:
#    kubectl create namespace cardano-preprod
#
# 3. Create secrets for preprod pool:
#    kubectl create secret generic preprod-forging-keys \
#      --from-file=kes.skey=path/to/preprod/kes.skey \
#      --from-file=vrf.skey=path/to/preprod/vrf.skey \
#      --from-file=node.cert=path/to/preprod/node.cert \
#      --namespace cardano-preprod
#
# 4. Deploy preprod block producer:
#    helm install cardano-preprod charts/cardano-node \
#      --namespace cardano-preprod \
#      --set forgeManager.secretName=preprod-forging-keys \
#      -f values/testnet-preprod.yaml
#
# 5. Monitor initial sync (with Mithril):
#    kubectl logs -f cardano-preprod-0 -c cardano-node -n cardano-preprod
#    # Should see Mithril snapshot restore messages
#
# 6. Check leader election:
#    kubectl get cardanoleaders -n cardano-preprod
#    kubectl describe cardanoleader cardano-leader-preprod-pool1test -n cardano-preprod
#
# 7. Monitor forge manager:
#    kubectl logs -f cardano-preprod-0 -c forge-manager -n cardano-preprod
#
# 8. Check metrics:
#    kubectl port-forward svc/cardano-preprod-forge-metrics 8000:8000 -n cardano-preprod
#    curl localhost:8000/metrics | grep cardano_
#
# ===========================================
# TESTING SCENARIOS
# ===========================================
# 1. Test leader election:
#    kubectl delete pod cardano-preprod-0 -n cardano-preprod
#    # Watch as cardano-preprod-1 becomes leader
#
# 2. Test credential distribution:
#    kubectl exec -it cardano-preprod-0 -c forge-manager -n cardano-preprod -- ls -la /ipc/
#    # Leader should have kes.skey, vrf.skey, node.cert
#
# 3. Test forging:
#    # Wait for full sync, then monitor blocks forged
#    kubectl exec -it cardano-preprod-0 -c cardano-node -n cardano-preprod -- \
#      cardano-cli query tip --testnet-magic 1
#
# ===========================================
# NETWORK MAGIC REFERENCE
# ===========================================
# Preprod: 1
# Preview: 2
# Mainnet: 764824073

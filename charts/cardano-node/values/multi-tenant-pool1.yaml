# Multi-Tenant Deployment - Pool 1
# This configuration demonstrates running multiple independent pools in the same Kubernetes cluster
# Each pool gets its own leases, CRDs, and metrics - completely isolated

# ===========================================
# REPLICA CONFIGURATION
# ===========================================
replicaCount: 3

# ===========================================
# CARDANO NODE CONFIGURATION
# ===========================================
cardanoNode:
  network: "mainnet"
  magic: "764824073"
  
  # Block producer mode
  blockProducer: true
  startAsNonProducing: true
  
  # Disable Mithril for production
  mithril:
    enabled: false
    restoreSnapshot: false

# ===========================================
# FORGE MANAGER V2.0 - MULTI-TENANT MODE
# ===========================================
forgeManager:
  enabled: true
  
  # Basic settings
  metricsPort: 8000
  socketWaitTimeout: 120
  sleepInterval: 10
  logLevel: "INFO"
  
  # ===========================================
  # MULTI-TENANT CONFIGURATION - POOL 1
  # ===========================================
  multiTenant:
    enabled: true  # REQUIRED for multi-tenant
    
    pool:
      # POOL 1 identification
      id: "pool1abc1111111111111111111111111111111111111111111111"  # Replace with Pool 1 ID
      idHex: ""  # Optional
      name: "Cardano Pool 1"
      ticker: "POOL1"
    
    application:
      type: "block-producer"
      environment: "production"
  
  # ===========================================
  # CLUSTER MANAGEMENT
  # ===========================================
  # Optional: Can also enable cluster management per pool
  clusterManagement:
    enabled: false  # Single cluster for this example
  
  # Legacy CRD configuration
  legacy:
    crd:
      cardanoLeader:
        enabled: true
        # Name will be auto-generated: cardano-leader-mainnet-pool1abc

# ===========================================
# STORAGE CONFIGURATION
# ===========================================
persistence:
  enabled: true
  size: 400Gi
  # storageClass: "fast-ssd"

# ===========================================
# RESOURCE CONFIGURATION
# ===========================================
resources:
  cardanoNode:
    limits:
      cpu: 4000m
      memory: 24Gi
    requests:
      cpu: 2000m
      memory: 20Gi
  
  forgeManager:
    limits:
      cpu: 500m
      memory: 1Gi
    requests:
      cpu: 200m
      memory: 512Mi

# ===========================================
# SERVICE CONFIGURATION
# ===========================================
service:
  p2p:
    type: LoadBalancer
    annotations: {}

# ===========================================
# MONITORING
# ===========================================
monitoring:
  enabled: true
  serviceMonitor:
    enabled: true
    interval: 30s
    labels:
      pool: pool1

# ===========================================
# POD LABELS
# ===========================================
podLabels:
  pool-id: "pool1abc"
  pool-ticker: "POOL1"
  tenant: "pool1"

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "12798"

# ===========================================
# POD ANTI-AFFINITY
# ===========================================
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - cardano-node
              - key: pool-id
                operator: In
                values:
                  - pool1abc
          topologyKey: kubernetes.io/hostname

# ===========================================
# DEPLOYMENT INSTRUCTIONS
# ===========================================
# This example shows running TWO INDEPENDENT POOLS in the same cluster
#
# 1. Install CRDs (once):
#    helm install cardano-forge-crds charts/cardano-forge-crds \
#      --namespace cardano-system --create-namespace
#
# 2. Create namespace:
#    kubectl create namespace cardano-multi-tenant
#
# 3. Create secrets for Pool 1:
#    kubectl create secret generic pool1-forging-keys \
#      --from-file=kes.skey=path/to/pool1/kes.skey \
#      --from-file=vrf.skey=path/to/pool1/vrf.skey \
#      --from-file=node.cert=path/to/pool1/node.cert \
#      --namespace cardano-multi-tenant
#
# 4. Deploy Pool 1:
#    helm install cardano-pool1 charts/cardano-node \
#      --namespace cardano-multi-tenant \
#      --set forgeManager.secretName=pool1-forging-keys \
#      -f values/multi-tenant-pool1.yaml
#
# 5. Deploy Pool 2 (see multi-tenant-pool2.yaml):
#    kubectl create secret generic pool2-forging-keys \
#      --from-file=kes.skey=path/to/pool2/kes.skey \
#      --from-file=vrf.skey=path/to/pool2/vrf.skey \
#      --from-file=node.cert=path/to/pool2/node.cert \
#      --namespace cardano-multi-tenant
#    
#    helm install cardano-pool2 charts/cardano-node \
#      --namespace cardano-multi-tenant \
#      --set forgeManager.secretName=pool2-forging-keys \
#      -f values/multi-tenant-pool2.yaml
#
# 6. Verify isolation:
#    # Check leases (should see separate leases per pool)
#    kubectl get leases -n cardano-multi-tenant
#    # Output: cardano-leader-mainnet-pool1abc, cardano-leader-mainnet-pool2xyz
#    
#    # Check CRDs (should see separate CRDs per pool)
#    kubectl get cardanoleaders -n cardano-multi-tenant
#    # Output: cardano-leader-mainnet-pool1abc, cardano-leader-mainnet-pool2xyz
#    
#    # Check pods
#    kubectl get pods -n cardano-multi-tenant
#    # Should see: cardano-pool1-0, cardano-pool1-1, cardano-pool1-2
#    #             cardano-pool2-0, cardano-pool2-1, cardano-pool2-2
#
# 7. Monitor per-pool metrics:
#    kubectl port-forward svc/cardano-pool1-forge-metrics 8001:8000 -n cardano-multi-tenant
#    curl localhost:8001/metrics | grep cardano_forging_enabled
#    # Should show pool_id="pool1abc..."
